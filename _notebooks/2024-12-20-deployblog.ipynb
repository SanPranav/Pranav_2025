{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "layout: post\n",
    "title: Big Ideas 1, 2, 4 \n",
    "description: A blog post about the work I did during Sprint 5 and Deployment.\n",
    "type: collab\n",
    "comments: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 1.1 Notes\n",
    "\n",
    "- I learned how Facebook has communicated to create nice projects.\n",
    "- The workplace area of Facebook is open and is created for communication to ensure that everyone is in sync or working together.\n",
    "\n",
    "## Answer the question:\n",
    "\n",
    "![Image](https://github.com/user-attachments/assets/96123fc2-c614-416e-954a-cabf75ff035a)\n",
    "\n",
    "### My answer: B\n",
    "\n",
    "**Why I chose this answer:**\n",
    "I chose this answer because I watched the video and saw how people would replicate this, such as people in Facebook that would actually collaborate to create large-scale projects, etc. This can lead to really cool things.\n",
    "\n",
    "## Takeaway notes:\n",
    "\n",
    "**Interpersonal Skills learned through collaboration:**\n",
    "- Communication\n",
    "- Consensus Building\n",
    "- Conflict Resolution\n",
    "- Negotiation\n",
    "\n",
    "**Good African Proverb I learned from this video:**\n",
    "\"If you want to go fast, go alone. If you want to go far, go together.\" - African Proverb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Notes\n",
    "\n",
    "### Describing the purpose of a computing innovation.\n",
    "\n",
    "Categories of Innovations:\n",
    "- **Applications:**\n",
    "  - Games \n",
    "  - Social Media\n",
    "  - Business\n",
    "  - Productivity\n",
    "- **Physical Devices:**\n",
    "  - Computers\n",
    "  - Smart Phones/tablets\n",
    "  - Smart \"things\"\n",
    "  - Wearables\n",
    "- **Systems:**\n",
    "  - E-commerce\n",
    "  - Cloud services\n",
    "  - E-mail\n",
    "\n",
    "### Guiding Questions:\n",
    "\n",
    "- Why does the computing innovation exist?\n",
    "- What problem(s) does the computing innovation solve?\n",
    "- What does the computing innovation allow us to do that we could not do before?\n",
    "\n",
    "### Day 2 Video:\n",
    "\n",
    "- Input output\n",
    "\n",
    "### Day 3 Video:\n",
    "\n",
    "- Explaining code\n",
    "\n",
    "### Example:\n",
    "\n",
    "<img src=\"https://github.com/user-attachments/assets/93c07601-c52f-4804-8da4-fcdfedb03663\" alt=\"Example Image\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 - Collaboration\n",
    "- **Importance**: Collaboration enhances problem-solving, creativity, and efficiency in programming.  \n",
    "- **Benefits**:  \n",
    "  - Helps in debugging and improving code.  \n",
    "  - Allows diverse perspectives and expertise.  \n",
    "  - Enables effective project management.  \n",
    "- **Techniques**:  \n",
    "  - **Pair Programming** – One writes code, the other reviews.  \n",
    "  - **Version Control** – Tools like Git help track changes.  \n",
    "  - **Agile Development** – Iterative approach to improve software.\n",
    "\n",
    "---\n",
    "\n",
    "## 1.4 - Identifying and Correcting Errors\n",
    "- **Types of Errors**:  \n",
    "  - **Syntax Errors** – Mistakes in grammar (e.g., missing `:` in Python).  \n",
    "  - **Logic Errors** – Code runs but produces incorrect results.  \n",
    "  - **Runtime Errors** – Errors occurring during execution (e.g., division by zero).  \n",
    "- **Debugging Strategies**:  \n",
    "  - **Print Statements** – Check values at different points.  \n",
    "  - **Rubber Duck Debugging** – Explain the code to find mistakes.  \n",
    "  - **Using Debugging Tools** – IDE debuggers, logging, and step-by-step execution.\n",
    "\n",
    "---\n",
    "\n",
    "## 1.5 - Program Documentation\n",
    "- **Why Document?**  \n",
    "  - Helps users and developers understand the code.  \n",
    "  - Aids in debugging and future modifications.  \n",
    "- **Best Practices**:  \n",
    "  - Use **comments** to describe functionality.  \n",
    "  - Write **meaningful variable names**.  \n",
    "  - Maintain a **README file** for project details.\n",
    "\n",
    "---\n",
    "\n",
    "## 1.6 - Testing Programs\n",
    "- **Testing Types**:  \n",
    "  - **Unit Testing** – Testing individual components of the code.  \n",
    "  - **Integration Testing** – Ensuring different parts work together.  \n",
    "  - **User Testing** – Real users test for usability.  \n",
    "- **Techniques**:  \n",
    "  - **Edge Case Testing** – Check extreme values (e.g., max/min inputs).  \n",
    "  - **Automated Testing** – Scripts that check for errors (e.g., `unittest` in Python).  \n",
    "\n",
    "---\n",
    "\n",
    "## 1.7 - Binary and Digital Data Representation\n",
    "- **Binary System**:  \n",
    "  - Computers store everything in **0s and 1s**.  \n",
    "  - Each digit (bit) represents **two states** (on/off, true/false).  \n",
    "- **Data Types in Binary**:  \n",
    "  - **Text** – ASCII/Unicode.  \n",
    "  - **Images** – Pixels stored as binary values (RGB).  \n",
    "  - **Sound** – Sampled and stored in digital format.  \n",
    "\n",
    "---\n",
    "\n",
    "## 1.8 - Using and Analyzing Data\n",
    "- **Big Data**: Large sets of data used for insights (e.g., social media trends).  \n",
    "- **Data Processing**:  \n",
    "  - **Cleaning Data** – Removing duplicates/errors.  \n",
    "  - **Sorting and Filtering** – Organizing data for better analysis.  \n",
    "  - **Visualization** – Charts and graphs to identify patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Idea 2: Data and Analysis (AP CSP)\n",
    "\n",
    "Data is the backbone of modern computing, enabling insights, decision-making, and automation. Big Idea 2 focuses on how data is collected, processed, and analyzed, helping us uncover patterns and make informed choices.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 - Binary and Data Representation\n",
    "\n",
    "### **What is Binary?**\n",
    "Computers store and process all data in **binary (0s and 1s)**. Each bit represents a state (on/off, true/false), and larger data is built from multiple bits.\n",
    "\n",
    "### **Data Types in Binary**\n",
    "- **Text** – Encoded using **ASCII (7-bit) or Unicode (UTF-8, UTF-16, UTF-32)**.\n",
    "- **Images** – Represented as pixels with **RGB (Red, Green, Blue) values**.\n",
    "- **Audio** – Stored as **digital sound waves**, sampled at regular intervals.\n",
    "- **Video** – A sequence of images (frames) with **audio and compression**.\n",
    "\n",
    "### **Converting Data to Binary**\n",
    "- **Decimal to Binary**: Divide by 2, recording remainders.\n",
    "- **Binary to Decimal**: Multiply each bit by powers of 2 and sum the results.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.2 - Data Compression\n",
    "\n",
    "### **Why Compress Data?**\n",
    "Data can take up large amounts of space, and compression reduces file size while maintaining usability.\n",
    "\n",
    "### **Types of Compression**\n",
    "1. **Lossless Compression** (No data loss)\n",
    "   - Uses patterns and redundancy to reduce size.\n",
    "   - **Examples**: PNG (images), FLAC (audio), ZIP (files).\n",
    "2. **Lossy Compression** (Some data loss)\n",
    "   - Removes unnecessary details to save space.\n",
    "   - **Examples**: JPEG (images), MP3 (audio), MP4 (video).\n",
    "\n",
    "### **Trade-offs in Compression**\n",
    "- **Lossless** keeps quality but results in larger files.\n",
    "- **Lossy** reduces size significantly but sacrifices detail.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.3 - Data and Metadata\n",
    "\n",
    "### **What is Metadata?**\n",
    "Metadata is **data about data**, providing additional context.\n",
    "\n",
    "### **Examples of Metadata**\n",
    "- **Image Metadata**: Resolution, camera model, location (EXIF).\n",
    "- **Web Pages**: Title, description, keywords (HTML meta tags).\n",
    "- **Files**: Date modified, size, type.\n",
    "\n",
    "### **Why is Metadata Important?**\n",
    "- Helps **organize and categorize** data.\n",
    "- Improves **searchability and filtering**.\n",
    "- Provides **context for analysis** (e.g., timestamps in transactions).\n",
    "\n",
    "---\n",
    "\n",
    "## 2.4 - Data Storage and Privacy\n",
    "\n",
    "### **Where is Data Stored?**\n",
    "- **Local Storage**: Hard drives, SSDs.\n",
    "- **Cloud Storage**: Remote servers managed by providers (Google Drive, Dropbox).\n",
    "- **Databases**: Structured storage for quick retrieval (SQL, NoSQL).\n",
    "\n",
    "### **Security Concerns**\n",
    "- **Encryption** protects sensitive data.\n",
    "- **Backups** prevent data loss.\n",
    "- **Access Control** ensures only authorized users can view/edit.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.5 - Large Data Sets\n",
    "\n",
    "### **What is Big Data?**\n",
    "Big data refers to **massive datasets** that require specialized tools for processing.\n",
    "\n",
    "### **Uses of Big Data**\n",
    "- **Predictive Analytics** – Forecasting trends (e.g., stock market, weather).\n",
    "- **Machine Learning** – AI models improve based on data (e.g., self-driving cars).\n",
    "- **Healthcare** – Patient data analysis for better treatments.\n",
    "\n",
    "### **Challenges in Big Data**\n",
    "- **Storage** – Requires large capacity (terabytes, petabytes).\n",
    "- **Processing Speed** – Needs distributed computing (Hadoop, Spark).\n",
    "- **Privacy** – Ethical concerns about data collection and usage.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.6 - Data Cleaning and Processing\n",
    "\n",
    "### **Why Clean Data?**\n",
    "Raw data often contains **errors, inconsistencies, and missing values**. Cleaning ensures accuracy before analysis.\n",
    "\n",
    "### **Data Cleaning Steps**\n",
    "1. **Remove Duplicates** – Avoid redundant entries.\n",
    "2. **Handle Missing Data** – Fill gaps with averages or remove incomplete entries.\n",
    "3. **Standardize Formats** – Convert all dates to a common format.\n",
    "4. **Correct Errors** – Fix typos and inconsistencies.\n",
    "\n",
    "### **Data Processing Techniques**\n",
    "- **Sorting and Filtering**: Organizing data for better analysis.\n",
    "- **Aggregation**: Summarizing large datasets (e.g., finding averages).\n",
    "- **Data Visualization**: Graphs and charts for better understanding.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.7 - Using Programs to Process Data\n",
    "\n",
    "### **Why Automate Data Processing?**\n",
    "Manual analysis is slow and inefficient. Programs can:\n",
    "- Process data **faster and more accurately**.\n",
    "- Handle **large datasets**.\n",
    "- Detect **patterns and trends**.\n",
    "\n",
    "### **Common Data Processing Methods**\n",
    "- **Spreadsheets** (Excel, Google Sheets) – Basic analysis tools.\n",
    "- **Programming (Python, R, SQL)** – More advanced data manipulation.\n",
    "- **APIs and Databases** – Automated data retrieval and updates.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.8 - Identifying Trends and Patterns\n",
    "\n",
    "### **How Do We Find Trends?**\n",
    "- **Sorting & Filtering**: Isolate relevant data.\n",
    "- **Grouping & Aggregation**: Summarize based on categories.\n",
    "- **Data Visualization**: Use graphs, heatmaps, and dashboards.\n",
    "\n",
    "### **Common Types of Trends**\n",
    "- **Seasonal Trends**: Sales increase during holidays.\n",
    "- **Cyclical Patterns**: Economic growth and recessions.\n",
    "- **Outliers**: Unusual spikes in data (e.g., sudden stock market crash).\n",
    "\n",
    "### **Real-World Applications**\n",
    "- **Social Media Analytics** – Track engagement trends.\n",
    "- **Healthcare Predictions** – Disease outbreak forecasting.\n",
    "- **Marketing Strategies** – Understanding customer behavior.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.9 - Bias in Data\n",
    "\n",
    "### **What is Data Bias?**\n",
    "Bias occurs when data collection, processing, or interpretation is **skewed or unfair**.\n",
    "\n",
    "### **Types of Bias**\n",
    "- **Selection Bias** – Sample isn't representative of the whole population.\n",
    "- **Confirmation Bias** – Data is interpreted to fit existing beliefs.\n",
    "- **Algorithmic Bias** – AI models favor certain groups due to biased training data.\n",
    "\n",
    "### **How to Reduce Bias?**\n",
    "- Use **diverse datasets**.\n",
    "- Apply **random sampling**.\n",
    "- Regularly **audit AI models**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.10 - Using Data Ethically\n",
    "\n",
    "### **Why is Ethical Data Use Important?**\n",
    "Data misuse can lead to **privacy violations, discrimination, and misinformation**.\n",
    "\n",
    "### **Ethical Considerations**\n",
    "- **Informed Consent** – Users should know how their data is used.\n",
    "- **Transparency** – Companies must disclose data practices.\n",
    "- **Security** – Protect sensitive information from breaches.\n",
    "\n",
    "### **Laws and Regulations**\n",
    "- **GDPR (General Data Protection Regulation)** – Protects EU citizens' data.\n",
    "- **CCPA (California Consumer Privacy Act)** – Gives consumers control over personal data.\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusion: The Power of Data**\n",
    "Data is transforming the world, from social media analytics to healthcare predictions. However, its use comes with **challenges like privacy, bias, and security**. Understanding how data is **collected, processed, and analyzed** is crucial for making informed and ethical decisions in the digital age.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Idea 4\n",
    "---\n",
    "\n",
    "# AWS Deployment Process for Backend/Database\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **AWS Account**: Get the active AWS account from Mr. Mortensen. [AWS](https://aws.amazon.com/).\n",
    "2. **IAM User**: Create an IAM user - Identity and Access Management, so that we have permissions we need.\n",
    "3. **AWS CLI**: Install and configure the AWS CLI on local machine. Follow the instructions [here](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html).\n",
    "\n",
    "## Test Server\n",
    "\n",
    "Ensure that we have a working frontend-to-backend test server. If it does not work locally, there is no need to try it on deployment.\n",
    "\n",
    "## Subdomain\n",
    "\n",
    "Setup DNS endpoint through AWS Route 53.\n",
    "\n",
    "```yml\n",
    "Server: https://prism.stu.nighthawkcodingsociety.com/\n",
    "Domain: stu.nighthawkcodingsociety.com\n",
    "Subdomain: prism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Port (Backend)\n",
    "\n",
    "Select a unique port for the application. Update all locations:\n",
    "\n",
    "- **main.py**: Prepare the localhost test server port to run on the same port for consistency.\n",
    "  ```python\n",
    "  if __name__ == \"__main__\":\n",
    "      app.run(debug=True, host=\"0.0.0.0\", port=\"8505\")\n",
    "  ```\n",
    "\n",
    "- **Dockerfile**: Prepare this file to run a server as a virtual machine on the deployment host.\n",
    "  ```dockerfile\n",
    "  FROM docker.io/python:3.11\n",
    "  WORKDIR /\n",
    "  RUN apt-get update && apt-get upgrade -y && \\\n",
    "      apt-get install -y python3 python3-pip git\n",
    "  COPY . /\n",
    "  RUN pip install --no-cache-dir -r requirements.txt\n",
    "  RUN pip install gunicorn\n",
    "  ENV GUNICORN_CMD_ARGS=\"--workers=1 --bind=0.0.0.0:8505\"\n",
    "  EXPOSE 8505\n",
    "  ENV FLASK_ENV=production\n",
    "  CMD [ \"gunicorn\", \"main:app\" ]\n",
    "  ```\n",
    "\n",
    "- **docker-compose.yml**: Prepare this file to serve as the “make” for Docker.\n",
    "  ```yaml\n",
    "  version: '3'\n",
    "  services:\n",
    "      web:\n",
    "          image: flask2025\n",
    "          build: .\n",
    "          env_file:\n",
    "              - .env\n",
    "          ports:\n",
    "              - \"8505:8505\"\n",
    "          volumes:\n",
    "              - ./instance:/instance\n",
    "          restart: unless-stopped\n",
    "  ```\n",
    "\n",
    "- **nginx_file**: Prepare this file for reverse proxy (the way this works is that the information is sent from the internet to the application and back to the requester.)\n",
    "  ```nginx\n",
    "  server {\n",
    "      listen 80;\n",
    "      listen [::]:80;\n",
    "      server_name prism.nighthawkcodingsociety.com;\n",
    "      location / {\n",
    "          proxy_pass http://localhost:8505;\n",
    "          if ($request_method = OPTIONS) {\n",
    "              add_header \"Access-Control-Allow-Credentials\" \"true\" always;\n",
    "              add_header \"Access-Control-Allow-Origin\"  \"https://nighthawkcoders.github.io\" always;\n",
    "              add_header \"Access-Control-Allow-Methods\" \"GET, POST, PUT, DELETE, OPTIONS, HEAD\" always;\n",
    "              add_header \"Access-Control-Allow-MaxAge\" 600 always;\n",
    "              add_header \"Access-Control-Allow-Headers\" \"Authorization, Origin, X-Origin, X-Requested-With, Content-Type, Accept\" always;\n",
    "              return 204;\n",
    "          }\n",
    "      }\n",
    "  }\n",
    "  ```\n",
    "\n",
    "## Port (Frontend)\n",
    "\n",
    "Prepare the frontend to access our domain and ports to match our localhost, port 8505, and domain settings.\n",
    "\n",
    "- **assets/api/config.js**:\n",
    "  ```javascript\n",
    "  export var pythonURI;\n",
    "  if (location.hostname === \"localhost\" || location.hostname === \"127.0.0.1\") {\n",
    "      pythonURI = \"http://localhost:8505\";\n",
    "  } else {\n",
    "      pythonURI = \"https://prism.stu.nighthawkcodingsociety.com\";\n",
    "  }\n",
    "  ```\n",
    "\n",
    "## Accessing AWS EC2\n",
    "\n",
    "Login to AWS Console using our account.\n",
    "Access EC2 Dashboard and launch an instance.\n",
    "Select CSP\n",
    "\n",
    "![Our EC2](https://i.ibb.co/PsVPh0WP/pako-e-Npdl-N1u-Gj-EQh-V9lt-Be9-Si-KRqjd-Uqh-QWSEg-I2b-AQqpqo-Mrs-Du-PHa-K-80-QSHv-Xq9t-Nl-Cu-MPOd-G.png)\n",
    "\n",
    "Alternatively, use Cockpit:\n",
    "\n",
    "At cockpit.stu.nighthawkcodingsociety.com\n",
    "Username is ubuntu\n",
    "Password hint is 3 Musketeers\n",
    "\n",
    "## Application Setup\n",
    "\n",
    "1. **Finding a Port**: Run `docker ps` to make sure port 8505 is open\n",
    "2. **On localhost setup Docker files using VSCode**: Make sure the Dockerfile and docker-compose.yml match port 8505 on AWS EC2.\n",
    "- Use docker-compose up in the repo folder\n",
    "- Access the server after it's done building in browser on localhost:8505\n",
    "\n",
    "## Server Setup\n",
    "\n",
    "1. **Clone backend repo**: `git clone https://github.com/illuminati1618/prism_backend.git`\n",
    "2. **Navigate to repo**: `cd prism_backend`\n",
    "3. **Build site**: `docker-compose up -d --build`\n",
    "4. **Test site**: `curl localhost:8505`\n",
    "\n",
    "## Route 53 DNS\n",
    "\n",
    "Go to AWS Route 53 and setup DNS subdomain for backend server.\n",
    "\n",
    "## Changing Code will require Deployment Updates\n",
    "\n",
    "1. **Run git pull before making changes**\n",
    "2. **Open terminal in VSCode and run python main.py**\n",
    "3. **Make changes that are needed**\n",
    "4. **Commit the changes locally**\n",
    "5. **Test docker-compose up or sudo docker-compose up in VSCode terminal**\n",
    "6. **Sync change from UI/git push from terminal**\n",
    "\n",
    "## Pulling Changes into AWS EC2 deployment\n",
    "\n",
    "1. **Navigate to repo**: `cd ~/prism_2025`\n",
    "2. **docker-compose down**\n",
    "3. **git pull**\n",
    "4. **Rebuild docker container**: `docker-compose up -d --build`\n",
    "\n",
    "## Troubleshooting checks on AWS EC2\n",
    "\n",
    "1. **Try to curl**: `curl localhost:8505`\n",
    "2. **Run docker-compose ps**\n",
    "3. **Run docker ps**\n",
    "\n",
    "# AWS Flowchart (How it works/Process)\n",
    "\n",
    "![Flowchart](https://i.ibb.co/PsVPh0WP/pako-e-Npdl-N1u-Gj-EQh-V9lt-Be9-Si-KRqjd-Uqh-QWSEg-I2b-AQqpqo-Mrs-Du-PHa-K-80-QSHv-Xq9t-Nl-Cu-MPOd-G.png)\n",
    "\n",
    "## Quick Notes on Deployment (From Mortenson's Slack Message)\n",
    "\n",
    "To login to the deployment server on AWS EC2 you will use cockpit backdoor.\n",
    "https://cockpit.stu.nighthawkcodingsociety.com/ \n",
    "\n",
    "The username for the account is shown in the image and is \"ubuntu\" in all lowercase.You will need to DM Mr. Mortenson if you will be Deployment admin for the 3 Musketeer password.\n",
    "\n",
    "## First Time Install (Steps in Order)\n",
    "\n",
    "### 1. **Run `./scripts/db_init.py`**\n",
    "- This script likely initializes the database by creating tables, inserting default values, or running migrations. This will reset the data tables.\n",
    "- To execute:\n",
    "  \n",
    "  ```bash\n",
    "  python3 ./scripts/db_init.py\n",
    "  ```\n",
    "  \n",
    "- Ensure you have the required dependencies installed:\n",
    "  \n",
    "  ```bash\n",
    "  pip install -r requirements.txt\n",
    "  ```\n",
    "\n",
    "### 2. **In your repo, run Docker commands**\n",
    "- Docker is used to containerize the application, ensuring a consistent environment.\n",
    "\n",
    "- **Build the Docker images:**\n",
    "  \n",
    "  ```bash\n",
    "  docker-compose build\n",
    "  ```\n",
    "  This creates or updates the necessary containers.\n",
    "\n",
    "- **Run the containers in detached mode (-d for background running):**\n",
    "  \n",
    "  ```bash\n",
    "  docker-compose up -d\n",
    "  ```\n",
    "  This starts the application and related services (like a database or web server).\n",
    "\n",
    "### 3. **Test your server, use `curl` to verify response**\n",
    "- Check if your container is running:\n",
    "  \n",
    "  ```bash\n",
    "  docker ps\n",
    "  ```\n",
    "  This lists all active containers and their assigned ports.\n",
    "\n",
    "- Send a request to your application to verify it's working:\n",
    "  \n",
    "  ```bash\n",
    "  curl localhost:8505\n",
    "  ```\n",
    "\n",
    "### **Security Note**\n",
    "- **Never** store passwords directly in your code.\n",
    "- Use `.env` files and **never commit them to GitHub**.\n",
    "- .gitignore should include `.env` to prevent accidental uploads.\n",
    "\n",
    "## NGINX & Certbot Setup\n",
    "\n",
    "### Route 53 DNS\n",
    "\n",
    "Go to AWS Route 53 and set up a DNS subdomain for the backend server.\n",
    "\n",
    "### NGINX Setup\n",
    "\n",
    "1. **Go to nginx directory and create an Nginx config file**:\n",
    "    \n",
    "    ```bash\n",
    "    cd /etc/nginx/sites-available\n",
    "    sudo nano prism\n",
    "    ```\n",
    "    \n",
    "2. **Add the following config**:\n",
    "    \n",
    "    ```nginx\n",
    "    server {\n",
    "        listen 80;\n",
    "        listen [::]:80;\n",
    "        server_name prism.stu.nighthawkcodingsociety.com;\n",
    "        location / {\n",
    "            proxy_pass http://localhost:8505;\n",
    "            if ($request_method = OPTIONS) {\n",
    "                add_header \"Access-Control-Allow-Credentials\" \"true\" always;\n",
    "                add_header \"Access-Control-Allow-Origin\"  \"https://nighthawkcoders.github.io\" always;\n",
    "                add_header \"Access-Control-Allow-Methods\" \"GET, POST, PUT, DELETE, OPTIONS, HEAD\" always;\n",
    "                add_header \"Access-Control-Allow-MaxAge\" 600 always;\n",
    "                add_header \"Access-Control-Allow-Headers\" \"Authorization, Origin, X-Origin, X-Requested-With, Content-Type, Accept\" always;\n",
    "                return 204;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "    \n",
    "3. **Save the file** (`Ctrl + X`, then `Y`, then `Enter`).\n",
    "    \n",
    "4. **Activate configuration**:\n",
    "    \n",
    "    ```bash\n",
    "    cd /etc/nginx/sites-enabled\n",
    "    sudo ln -s /etc/nginx/sites-available/prism /etc/nginx/sites-enabled\n",
    "    ```\n",
    "    \n",
    "5. **Check for all proper configs and restart Nginx**:\n",
    "    \n",
    "    ```bash\n",
    "    sudo nginx -t\n",
    "    sudo systemctl restart nginx\n",
    "    ```\n",
    "    \n",
    "6. **Test if Nginx is serving requests**:  \n",
    "    Open **[http://prism.stu.nighthawkcodingsociety.com](http://prism.stu.nighthawkcodingsociety.com/)** in our browser.\n",
    "\n",
    "### Certbot Configuration for HTTPS\n",
    "\n",
    "Here are all the steps we will follow to install Certbot to deploy our site\n",
    "\n",
    "1. **Install Certbot**:\n",
    "    \n",
    "    ```bash\n",
    "    sudo apt-get install certbot python3-certbot-nginx\n",
    "    ```\n",
    "    \n",
    "2. **Run Certbot to get SSL certificate**:\n",
    "    \n",
    "    ```bash\n",
    "    sudo certbot --nginx\n",
    "    ```\n",
    "    \n",
    "3. **Follow the prompts**:\n",
    "    - Select `prism.stu.nighthawkcodingsociety.com` from the list.\n",
    "    - Choose option `2` because it will redirect us from HTTP to HTTPS, which is more secure.\n",
    "4. **Restart Nginx**:\n",
    "    \n",
    "    ```bash\n",
    "    sudo systemctl restart nginx\n",
    "    ```\n",
    "    \n",
    "5. **Test HTTPS access**:  \n",
    "    Open **[https://prism.stu.nighthawkcodingsociety.com](https://prism.stu.nighthawkcodingsociety.com/)** in our browser.\n",
    "\n",
    "## Updating Deployment\n",
    "\n",
    "### Changing Code in VSCode\n",
    "\n",
    "Steps:\n",
    "1. **Run `git pull` before making changes**.\n",
    "2. **Open terminal in VSCode and run `python main.py`**.\n",
    "3. **Make changes that are needed**.\n",
    "4. **Commit the changes locally**.\n",
    "5. **Test `docker-compose up` or `sudo docker-compose up` in VSCode terminal**.\n",
    "6. **Push changes to GitHub**.\n",
    "\n",
    "### Pulling Changes into AWS EC2 Deployment\n",
    "\n",
    "1. **Navigate to repo**:\n",
    "    \n",
    "    ```bash\n",
    "    cd ~/prism_2025\n",
    "    ```\n",
    "    \n",
    "2. **Stop running containers**:\n",
    "    \n",
    "    ```bash\n",
    "    docker-compose down\n",
    "    ```\n",
    "    \n",
    "3. **Pull the latest code**:\n",
    "    \n",
    "    ```bash\n",
    "    git pull\n",
    "    ```\n",
    "    \n",
    "4. **Rebuild the docker container**:\n",
    "    \n",
    "    ```bash\n",
    "    docker-compose up -d --build\n",
    "    ```\n",
    "\n",
    "## Debugging NGINX\n",
    "\n",
    "- If something fails, we will **check Nginx logs**:\n",
    "    \n",
    "    ```bash\n",
    "    sudo tail -f /var/log/nginx/error.log\n",
    "    ```\n",
    "\n",
    "## Notes from CB Big Idea 4:\n",
    "\n",
    "The internet is just a network of connected computers, and AWS provides a bunch of services such as compute, storage, and networking.\n",
    "\n",
    "### TCP handshake to establish a connection:\n",
    "<br>\n",
    "<img src=\"https://i.ibb.co/4nrSWrrQ/676fffa13937ff6a6bdaa846-627cb3d4fcfd563ee9f2d43d-How-does-TCP-work.jpg\">\n",
    "<br>\n",
    "\n",
    "### What happens when you open a webpage hosted on AWS:\n",
    "\n",
    "When you open a webpage hosted on AWS, your browser sends a request through the Internet to a remote server on AWS. Routers and switches help forward the packets until they reach the AWS server, which returns the webpage data. This process uses TCP/IP protocols and handshake to ensure reliable transfer. Once the data arrives back at your computer, the browser displays the webpage content.\n",
    "<br>\n",
    "The network layer of the TCP/IP protocol is responsible for accepting and delivering the packets that contain the data of our website.\n",
    "\n",
    "## Pranav's Notes for Tuesday Tech Talk (2/4/2025)\n",
    "\n",
    "### Start Deployment Procedures:\n",
    "\n",
    "### System Info (Image 1):\n",
    "- Go to the terminal to access the machine.\n",
    "- Now go to Amazon.\n",
    "\n",
    "### DNS & Routing:\n",
    "- Anvay handled this part to find our **route, type, alias, and IP address** to locate our Prism service.\n",
    "- **IP address** is a way to register our address.\n",
    "- Right now, we are on an **intranet**.\n",
    "  - **Intranet** = local to campus.\n",
    "  - **Internet** = external/global.\n",
    "- Anvay already got the **DNS** set up.\n",
    "- The websites are already assigned.\n",
    "- We have **different names for different servers**.\n",
    "- One of us has to handle this (**Anvay, the nonchalant sigma**).\n",
    "- **Current setup:**\n",
    "  - We should have a **subdomain**: `Prism`.\n",
    "  - Then, we type our **IP address** (Anvay’s thing).\n",
    "- **Make sure the IP address is the exact same.**\n",
    "- **Funny Moment:** The sub heard **PRISON instead of PRISM** \n",
    "- **Final step:** Ensure a **friendly address** is registering to our IP name.\n",
    "  - Often, we call these our **domain names**, but it’s actually our **URL**.\n",
    "\n",
    "### Understanding What We Did:\n",
    "- Everybody there?\n",
    "- **What did we just do?**\n",
    "  - This is a **database**, and we created an **A record** called `Prism`.\n",
    "  - This maps to an **IP address**.\n",
    "  - We have a bunch of **nonhumans** in our class (`studybuddy` and `prism team` are normal).\n",
    "  - **DNS maps record names to computers.**\n",
    "  - If it's a **named service record**, it looks through other routes to understand the rest of the database.\n",
    "\n",
    "### AWS Setup:\n",
    "1. Go to **EC2**.\n",
    "2. On EC2, go to **Instances Running** and scroll to the right to find the **Elastic IP**.\n",
    "3. **We created a machine on AWS that has its own IP.**\n",
    "4. Now, we’ll **launch a new instance**:\n",
    "   - Name it `xxx`.\n",
    "   - Pick **Operating System**.\n",
    "   - Choose **Micro/Nano** instance type.\n",
    "   - Set **disk size**, then click **Launch Instance**.\n",
    "5. **Reminder:** Every one of these hardware instances **costs money per hour**.\n",
    "\n",
    "### Additional Notes:\n",
    "- **Permissions:** We **don’t** give blanket permissions.\n",
    "- **Backend Setup:**\n",
    "  - Talks about **fetches** and **directories**.\n",
    "  - **\"Better than candy\"** (??).\n",
    "  - We need to **clone ours**—only **one person** has to do it.\n",
    "  - **Stick with the naming convention.**\n",
    "\n",
    "## Transcript of 5 minute clip from Pranav's Laptop (This is not corrected this is purely what the laptop heard)\n",
    "### Transcript by Pranav Santhosh\n",
    "\n",
    "0:00: You're a regularly scheduled programming we're gonna finish these files up and we're gonna commit them.\n",
    "\n",
    "0:09: We're gonna make sure we commit this file over here, so commit it, but we need to commit these so we can go forward.\n",
    "\n",
    "0:16: Once you're committed and you have your .env file over in your other directory, you should be able to do a document in here.\n",
    "\n",
    "0:31: The objective here is what we wanna do is we're gonna do `ps` here.\n",
    "\n",
    "0:36: These are all the people that are successful today.\n",
    "\n",
    "0:40: You can see some 2s, a 0, which is me.\n",
    "\n",
    "0:45: Right, 113234.\n",
    "\n",
    "0:52: See if you can guys set a record, right?\n",
    "\n",
    "0:55: All right, all right, so here we go.\n",
    "\n",
    "1:05: I'm gonna, I'm just gonna shut mine down right now.\n",
    "\n",
    "1:10: You don't need to do this because I'm, I'm up, so I gotta, I gotta go down `docker-compose down` and then I'm gonna do `docker-compose up`, you guys all need to do this.\n",
    "\n",
    "1:28: Wait, wait, wait, wait, hold on, don't do it yet.\n",
    "\n",
    "1:31: Do a `git pull` because you're gonna get all your new files, right?\n",
    "\n",
    "1:36: And then you're gonna do a `docker-compose up`.\n",
    "\n",
    "1:41: Cool, mine were up today, but you should, you should, you should see a little like red things and green things going on there.\n",
    "\n",
    "1:51: Did you guys get some red things and green things, right?\n",
    "\n",
    "1:54: If you didn't get any red things and green things, you messed up.\n",
    "\n",
    "1:59: All right, then you're gonna do `docker-compose up`.\n",
    "\n",
    "2:02: I was really fast because I already did it.\n",
    "\n",
    "2:10: All right, this might take a little while.\n",
    "\n",
    "2:14: Anybody building yet?\n",
    "\n",
    "2:15: Who's with me?\n",
    "\n",
    "2:17: Good, good, you're like just sit here and look at the wall.\n",
    "\n",
    "2:25: You need an apple.\n",
    "\n",
    "2:28: All right, so what you're doing here is you're building your project.\n",
    "\n",
    "2:35: So what I'm gonna do is I'm gonna look to pull that building we're gonna look at the Dockerfile.\n",
    "\n",
    "2:38: We're gonna look at the Dockerfile while building so we know what's happening.\n",
    "\n",
    "2:56: I don't"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
